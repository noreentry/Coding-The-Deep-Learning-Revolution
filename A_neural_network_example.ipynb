{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A neural network example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiensu/Coding-The-Deep-Learning-Revolution/blob/master/A_neural_network_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "x_qgt2_X69kC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kXgDcAPH0WSV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "damJEACq05OA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Check data\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2lilKiSX2aGe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The x data is the image information – 60,000 images of 28 x 28 pixels size in the training set. The\n",
        "images are grayscale (i.e black and white) with maximum values, specifying the intensity of whites,\n",
        "of 255. The x data will need to be scaled so that it resides between 0 and 1, as this improves training\n",
        "efficiency. The y data is the matching image labels – signifying what digit is displayed in the image.\n",
        "This will need to be transformed to “one hot” format."
      ]
    },
    {
      "metadata": {
        "id": "ha-GHjwX2cCE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract the training data in batches of samples\n",
        "def get_batch(x_data, y_data, batch_size):\n",
        "  idxs = np.random.randint(0, len(y_data), batch_size)\n",
        "  return x_data[idxs, :, :], y_data[idxs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7H32cDNs6kaa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Python optimisation variables\n",
        "learning_rate = 0.5\n",
        "epochs = 50\n",
        "batch_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tOKJTqVK6zhJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Declare the training data placeholders\n",
        "x = tf.placeholder(tf.float32, [None, 28, 28])\n",
        "# Reshape input x - for 28x28 pixels = 274\n",
        "x_rs = tf.reshape(x, [-1, 784])\n",
        "# Scale the input data (maximum is 1.0, minimum is 0.0)\n",
        "x_sc = tf.div(x_rs, 255.0)\n",
        "# Declare the output data placeholder - 10 digits\n",
        "y = tf.placeholder(tf.int64, [None, 1])\n",
        "# Convert the y data to one hot values\n",
        "y_one_hot = tf.reshape(tf.one_hot(y, 10), [-1, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bxrd6X1u8Te2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Declare the weights connecting the input to the hidden layer\n",
        "W1 = tf.Variable(tf.random_normal([784, 300], stddev=0.03), name='W1')\n",
        "b1 = tf.Variable(tf.random_normal([300]), name='b1')\n",
        "\n",
        "# Declare the weights connecting the hidden layer to the output layer\n",
        "W2 = tf.Variable(tf.random_normal([300, 10], stddev=0.03), name='W2')\n",
        "b2 = tf.Variable(tf.random_normal([10]), name='b2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qyabuZ5wCS9R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Calculate the output of hidden layer\n",
        "hidden_out = tf.add(tf.matmul(x_sc, W1), b1)\n",
        "hidden_out = tf.nn.relu(hidden_out)\n",
        "\n",
        "# Calculate the hidden layer out - no activation function applied\n",
        "logits = tf.add(tf.matmul(hidden_out, W2), b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jNGcu9lnHuas",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the cost function which we are going to train the model on\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_one_hot, logits=logits))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "je-qVVCmKW7u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Add an optimiser\n",
        "optimiser = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oEEWi9OfOESG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Finally setup the initialisation operator\n",
        "init_op = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1EFHUn7tObRt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define an accuracy assesment operation\n",
        "correct_prediction = tf.equal(tf.argmax(y_one_hot, 1), tf.argmax(logits, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pcl1jUV2Q_xT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Train the network"
      ]
    },
    {
      "metadata": {
        "id": "BzRgnnrDRC0P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Start the session\n",
        "with tf.Session() as sess:\n",
        "  # initialise the variables\n",
        "  sess.run(init_op)\n",
        "  total_batch = int(len(y_train)/batch_size)\n",
        "  for epoch in range(epochs):\n",
        "    avg_cost = 0\n",
        "    for i in range(total_batch):\n",
        "      batch_x, batch_y = get_batch(x_train, y_train, batch_size=batch_size)\n",
        "      _,c = sess.run([optimiser, cross_entropy], feed_dict={x:batch_x, y:batch_y.reshape(-1,1)})\n",
        "      avg_cost += c/total_batch\n",
        "      acc = sess.run(accuracy, feed_dict={x:x_test, y:y_test.reshape(-1,1)})\n",
        "    print(\"Epoch: {}, cost={:.3}, test set accuracy={:.3f}%\".format(epoch+1, avg_cost, acc*100))\n",
        "  print(\"\\nTraining complete!\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}